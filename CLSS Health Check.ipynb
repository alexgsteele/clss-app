{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea5216f",
   "metadata": {
    "papermill": {
     "duration": 0.004425,
     "end_time": "2024-08-15T00:28:00.992198",
     "exception": false,
     "start_time": "2024-08-15T00:28:00.987773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CLSS Health Check Service\n",
    "\n",
    "The purpose of this notebook is to validate the status of content that is registered in the data library. The notebook can be configured to run on a regular schedule (e.g., hourly) and will also be available to be run on-demand.\n",
    "\n",
    "During operation, the process interrogates registered content to gather its status (i.e. operational/active, not operational) and updates the Item table in the CLSS Feature Service. \n",
    "\n",
    "**Prior to running the deployment script, update the featureServiceItemID variable to reflect the Item ID of the CLSS feature service deployed to your organization.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a552a7f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T00:28:00.998979Z",
     "iopub.status.busy": "2024-08-15T00:28:00.998104Z",
     "iopub.status.idle": "2024-08-15T00:28:01.975333Z",
     "shell.execute_reply": "2024-08-15T00:28:01.974632Z"
    },
    "papermill": {
     "duration": 0.982688,
     "end_time": "2024-08-15T00:28:01.977496",
     "exception": false,
     "start_time": "2024-08-15T00:28:00.994808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ## ## ## ## ## ## ## ## ## ## ## ## ## ## \n",
    "## Import Dependencies\n",
    "## ## ## ## ## ## ## ## ## ## ## ## ## ## ## \n",
    "import urllib.request\n",
    "from urllib.parse import urlparse\n",
    "import urllib\n",
    "import json\n",
    "from arcgis import GIS\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c19d4c",
   "metadata": {
    "papermill": {
     "duration": 0.00195,
     "end_time": "2024-08-15T00:28:01.981661",
     "exception": false,
     "start_time": "2024-08-15T00:28:01.979711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b81b486a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T00:28:01.986247Z",
     "iopub.status.busy": "2024-08-15T00:28:01.985881Z",
     "iopub.status.idle": "2024-08-15T00:28:02.421126Z",
     "shell.execute_reply": "2024-08-15T00:28:02.419447Z"
    },
    "papermill": {
     "duration": 0.439523,
     "end_time": "2024-08-15T00:28:02.422785",
     "exception": false,
     "start_time": "2024-08-15T00:28:01.983262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/arcgis/gis/__init__.py:731: UserWarning: You are logged on as AadhikariGH with an administrator role, proceed with caution.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Connect to GIS\n",
    "#username = ''\n",
    "#password = ''\n",
    "#gis = GIS(\"https://arcgis.com\", username, password)\n",
    "gis = GIS('home')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af09f00",
   "metadata": {
    "papermill": {
     "duration": 0.003501,
     "end_time": "2024-08-15T00:28:02.428301",
     "exception": false,
     "start_time": "2024-08-15T00:28:02.4248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af87a9ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T00:28:02.433281Z",
     "iopub.status.busy": "2024-08-15T00:28:02.433036Z",
     "iopub.status.idle": "2024-08-15T00:28:02.442717Z",
     "shell.execute_reply": "2024-08-15T00:28:02.442089Z"
    },
    "papermill": {
     "duration": 0.014078,
     "end_time": "2024-08-15T00:28:02.444092",
     "exception": false,
     "start_time": "2024-08-15T00:28:02.430014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getItemSourceInfo(itemurl):\n",
    "    \"\"\"\n",
    "    Function to return the status of online content,\n",
    "    checking both HTTP status code and response content for errors\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    itemurl : string\n",
    "        Web-accessible URL \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A list containing [HTTP status code, description, is_operational]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        url = itemurl + '?f=pjson'\n",
    "\n",
    "        try:\n",
    "            with urllib.request.urlopen(url) as response:\n",
    "                responseCode = response.getcode()\n",
    "                \n",
    "    \n",
    "                if responseCode not in [200, 401, 403]:\n",
    "                    return [responseCode, f'HTTP error: {responseCode}', False]\n",
    "                \n",
    "    \n",
    "                if responseCode in [401, 403]:\n",
    "                    return [responseCode, f'Authorization required ({responseCode}), but considered operational', True]\n",
    "                \n",
    "                # For 200 responses, we also need to check the content. An example could be a layer view id that doesn't exist but the response would still be 200 and the body would include an error\n",
    "                try:\n",
    "                    result = response.read().decode(\"utf-8\")\n",
    "                    \n",
    "\n",
    "                    try:\n",
    "                        data = json.loads(result)\n",
    "                        \n",
    "\n",
    "                        if 'error' in data:\n",
    "                            error_code = data['error'].get('code', 'unknown')\n",
    "                            error_details = '. '.join(data['error'].get('details', [])) if 'details' in data['error'] else str(data['error'])\n",
    "                            return [error_code, f'JSON error: {error_details}', False]\n",
    "                        \n",
    "                        return [200, 'Operational', True]\n",
    "                        \n",
    "                    except json.JSONDecodeError:\n",
    "                        return [200, 'Operational (non-JSON response)', True]\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    return [200, f'Content processing error: {str(e)}', False]\n",
    "\n",
    "        except urllib.error.HTTPError as e:\n",
    "            return [e.code, e.msg, e.code in [200, 401, 403]]\n",
    "\n",
    "        except urllib.error.URLError as e:\n",
    "            # URL error (DNS failure, connection refused, etc.)\n",
    "            if hasattr(e, 'reason'):\n",
    "                return ['unknown', str(e.reason), False]\n",
    "            elif hasattr(e, 'code'):\n",
    "                return [e.code, '', e.code in [200, 401, 403]]\n",
    "            return ['unknown', 'URL Error', False]\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch-all for any other errors\n",
    "        return ['unknown', str(e), False]\n",
    "\n",
    "def is_valid_url(url):\n",
    "    \"\"\"Check if a string is a valid URL\"\"\"\n",
    "    try:\n",
    "        result = urlparse(url)\n",
    "#         check if it includes http/https and network domain\n",
    "        return all([result.scheme, result.netloc])\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def process_items(clssItemTable, clssItems):\n",
    "    \"\"\"Process each item and update its status in the table\"\"\"\n",
    "    batch_size = 100\n",
    "    batch_updates = []\n",
    "    updated_count = 0\n",
    "    currentTime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    for item in clssItems:\n",
    "        # Retrieve attributes\n",
    "        itemGlobalId = item.attributes['GlobalID']\n",
    "        itemUrl = item.attributes['URL']\n",
    "        itemName = item.attributes['Name']\n",
    "        \n",
    "        if itemUrl and is_valid_url(itemUrl):\n",
    "            print(f'Processing: {itemName}')\n",
    "            \n",
    "            # Get status information\n",
    "            statusCode, statusDesc, is_operational = getItemSourceInfo(itemUrl)\n",
    "            print(f\"Status: {statusCode} - {statusDesc} - Operational: {is_operational}\")\n",
    "            \n",
    "            # Prepare update with appropriate health status\n",
    "            if is_operational:\n",
    "                detail = 'Item Healthcheck Successful'\n",
    "                statusVal = 1\n",
    "            else:\n",
    "                detail = f'Service error: {statusCode}. {statusDesc}'\n",
    "                statusVal = 0\n",
    "\n",
    "            updateItem = {\n",
    "                \"attributes\": {\n",
    "                    'GlobalID': itemGlobalId,\n",
    "                    'HealthcheckUpdate': str(currentTime),\n",
    "                    'HealthcheckDetails': detail,\n",
    "                    'HealthcheckStatus': statusVal\n",
    "                }\n",
    "            }\n",
    "\n",
    "            batch_updates.append(updateItem)\n",
    "\n",
    "            # Send batch if it reaches threshold\n",
    "            if len(batch_updates) >= batch_size:\n",
    "                try:\n",
    "                    clssItemTable.edit_features(updates=batch_updates, use_global_ids=True)\n",
    "                    updated_count += len(batch_updates)\n",
    "                    batch_updates = []\n",
    "                except Exception as e:\n",
    "                    print(f\"ERROR during batch update: {e}\")\n",
    "        else:\n",
    "            print(f\"Invalid URL: {itemUrl}\")\n",
    "\n",
    "    # Final flush of remaining items\n",
    "    if batch_updates:\n",
    "        try:\n",
    "            clssItemTable.edit_features(updates=batch_updates, use_global_ids=True)\n",
    "            updated_count += len(batch_updates)\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR during final batch update: {e}\")\n",
    "\n",
    "    print('> Total count of items updated:', updated_count)\n",
    "    print('>> Health check complete.')\n",
    "    return updated_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a924bd",
   "metadata": {
    "papermill": {
     "duration": 0.001754,
     "end_time": "2024-08-15T00:28:02.447571",
     "exception": false,
     "start_time": "2024-08-15T00:28:02.445817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Process ITEMs in the CLSS Feature Service\n",
    "\n",
    "1. Connect to the feature service containing items registered in the CLSS Data Library. \n",
    "2. Iterate through items and update the health check status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f0e389",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "featureServiceItemID = \"e345bbe0a23c42a19ebd52d01ac32831\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dbff3c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T00:28:02.452228Z",
     "iopub.status.busy": "2024-08-15T00:28:02.451989Z",
     "iopub.status.idle": "2024-08-15T00:28:03.367728Z",
     "shell.execute_reply": "2024-08-15T00:28:03.366838Z"
    },
    "papermill": {
     "duration": 0.920777,
     "end_time": "2024-08-15T00:28:03.369986",
     "exception": false,
     "start_time": "2024-08-15T00:28:02.449209",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter the Feature Service ID in the code below\n",
    "clssService = gis.content.get(featureServiceItemID)\n",
    "clssItemTable = clssService.tables[3]  ## ITEM table\n",
    "clssItems = clssItemTable.query(where=\"Status = 1\", out_fields=\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e66464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T00:28:03.375962Z",
     "iopub.status.busy": "2024-08-15T00:28:03.375712Z",
     "iopub.status.idle": "2024-08-15T00:28:14.234079Z",
     "shell.execute_reply": "2024-08-15T00:28:14.233092Z"
    },
    "papermill": {
     "duration": 10.863183,
     "end_time": "2024-08-15T00:28:14.235665",
     "exception": false,
     "start_time": "2024-08-15T00:28:03.372482",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: FEMA Open Shelters\n",
      "Status: 200 - Operational - Operational: True\n",
      "Processing: World Traffic Map\n",
      "Status: 499 - JSON error:  - Operational: False\n",
      "Processing: IPAWS Events\n",
      "Status: 200 - Operational - Operational: True\n",
      "Processing: EPA Facility Registry Service - Superfund Nation Priorities List (SEMS_NPL)\n",
      "Status: 200 - Operational - Operational: True\n",
      "Processing: Hospitals Medical Centers\n",
      "Status: 200 - Operational - Operational: True\n",
      "Processing: Outer Continental Shelf Oil and Natural Gas Platforms - Gulf of America Region\n",
      "Status: 200 - Operational - Operational: True\n",
      "Processing: Nuclear Power Plants\n",
      "Status: 200 - Operational - Operational: True\n",
      "Processing: State Activation Levels\n",
      "Status: 200 - Operational - Operational: True\n",
      "Processing: National Bridge Inventory\n",
      "Status: 200 - Operational - Operational: True\n",
      "Processing: National Inventory of Dams\n",
      "Status: 200 - Operational - Operational: True\n",
      "Processing: Emergency Shelter Population\n",
      "Status: 200 - Operational - Operational: True\n",
      "Processing: FCC Disaster Information Reporting System (DIRS)\n",
      "Status: 200 - Operational - Operational: True\n",
      "Processing: Live Stream Gauges\n",
      "Status: 200 - Operational - Operational: True\n",
      "Processing: USA Airports\n",
      "Status: 200 - Operational - Operational: True\n",
      "Processing: Current Wildfires\n",
      "Status: 200 - Operational - Operational: True\n",
      "Processing: Fire Forecast Zones\n",
      "Status: 400 - JSON error: The requested layer (layerId: 24) was not found. - Operational: False\n",
      "Processing: Power Outage Dashboard\n",
      "Status: 403 - Forbidden - Operational: True\n",
      "> Total count of items updated: 17\n",
      ">> Health check complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_items(clssItemTable, clssItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067e3855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Standard",
   "notebookRuntimeVersion": "7.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.609401,
   "end_time": "2024-08-15T00:28:14.649351",
   "environment_variables": {},
   "exception": null,
   "input_path": "/tmp/arcgis/.tasks/a80f611d26aa4ecaaa8dcdf7c99569b3/c32461b1af2d485a8ab3cae7e51a0193.ipynb",
   "output_path": "/tmp/arcgis/.tasks/a80f611d26aa4ecaaa8dcdf7c99569b3/output.ipynb",
   "start_time": "2024-08-15T00:28:00.03995",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
